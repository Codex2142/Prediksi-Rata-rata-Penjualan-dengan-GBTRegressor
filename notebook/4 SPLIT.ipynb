{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0dad090",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import max, date_sub\n",
    "from pyspark.sql.functions import expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "892dd4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"M5-Split\")\n",
    "    .master(\"local[2]\")\n",
    "    .config(\"spark.driver.memory\", \"6g\")\n",
    "    .config(\"spark.executor.memory\", \"6g\")\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"32\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1e88356",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet(\"../dataset/cooked/2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc188b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: date (nullable = true)\n",
      " |-- item_id: string (nullable = true)\n",
      " |-- store_id: string (nullable = true)\n",
      " |-- sales: integer (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      " |-- event: string (nullable = true)\n",
      " |-- weekday: string (nullable = true)\n",
      " |-- lag_7: integer (nullable = true)\n",
      " |-- lag_14: integer (nullable = true)\n",
      " |-- lag_28: integer (nullable = true)\n",
      " |-- rolling_mean_7: double (nullable = true)\n",
      " |-- rolling_mean_28: double (nullable = true)\n",
      " |-- price_change: double (nullable = true)\n",
      " |-- dayofweek: integer (nullable = true)\n",
      " |-- weekofyear: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- is_weekend: integer (nullable = true)\n",
      " |-- event_idx: double (nullable = true)\n",
      "\n",
      "+----------+\n",
      "|      date|\n",
      "+----------+\n",
      "|2014-05-04|\n",
      "|2011-04-24|\n",
      "|2015-02-07|\n",
      "+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()\n",
    "df.select(\"date\").show(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79ce5781",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_date = df.selectExpr(\"date_sub(max(date), 28)\").collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69dec6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df.filter(df.date < cutoff_date)\n",
    "test_df  = df.filter(df.date >= cutoff_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d71f7d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "| min(date)| max(date)|\n",
      "+----------+----------+\n",
      "|2011-02-26|2016-03-26|\n",
      "+----------+----------+\n",
      "\n",
      "+----------+----------+\n",
      "| min(date)| max(date)|\n",
      "+----------+----------+\n",
      "|2016-03-27|2016-04-24|\n",
      "+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.selectExpr(\"min(date)\", \"max(date)\").show()\n",
    "test_df.selectExpr(\"min(date)\", \"max(date)\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "586783fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.rdd.getNumPartitions()\n",
    "test_df.rdd.getNumPartitions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84bdd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    train_df\n",
    "    .repartition(4)\n",
    "    .write\n",
    "    .mode(\"overwrite\")\n",
    "    .parquet(\"../dataset/cooked/3/train\")\n",
    ")\n",
    "\n",
    "(\n",
    "    test_df\n",
    "    .repartition(4)\n",
    "    .write\n",
    "    .mode(\"overwrite\")\n",
    "    .parquet(\"../dataset/cooked/3/test\")\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
